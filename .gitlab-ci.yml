#demo9eddsfdfdssd

# TODO
# include:
#   - local: "pipeline/stages/eurosPart.yml"
#   - local: "pipeline/stages/timsPart.yml"

variables:
  GIT_STRATEGY: clone   


stages:
  - start_services
  - extract_metadata
  - run_pen_test
  - save_results
  - visualize

# Stage 1 start target service
start_services:
  image: docker:latest
  stage: start_services

  services:
    - docker:dind
  tags:
    - bin-runner
  script:
    - echo "Checking if Juice Shop is already running..."
    - docker ps -a | grep "juice-shop" && docker rm -f juice-shop || echo "No existing container."
    
    # Create a simpler cleanup script focusing on Docker
    - |
      cat > cleanup_port.sh << 'EOF'
      #!/bin/bash
      # First try to stop any container using port 3000
      echo "Removing any containers using port 3000..."
      docker ps -q --filter publish=3000 | xargs -r docker stop
      docker ps -q --filter publish=3000 | xargs -r docker rm
      
      # If port is still in use, try to use a different port
      if lsof -i :3000 >/dev/null 2>&1 || netstat -tuln 2>/dev/null | grep -q ":3000 "; then
        echo "Port 3000 is still in use by a system process - will use port 3001 instead"
        export JUICE_PORT=3001
      else
        export JUICE_PORT=3000
      fi
      echo "JUICE_PORT=$JUICE_PORT" > port.env
      EOF
    
    - chmod +x cleanup_port.sh
    - ./cleanup_port.sh
    - source port.env || export JUICE_PORT=3001
    
    # Start Juice Shop with the decided port
    - echo "Starting Juice Shop on port $JUICE_PORT..."
    - docker run -d --name juice-shop -p $JUICE_PORT:3000 bkimminich/juice-shop:latest-arm
    
    - sleep 5
    - docker ps
    - echo "Juice Shop running on port $JUICE_PORT"
    
    # Update any URLs in configurations to match the chosen port
    - |
      if [ "$JUICE_PORT" != "3000" ]; then
        echo "Port was changed to $JUICE_PORT - updating any test URLs..."
        find . -type f -name "*.zst" -o -name "*.json" | xargs -r sed -i "s/localhost:3000/localhost:$JUICE_PORT/g" || true
      fi


# Stage 2 extract necessary metadata
extract_metadata:
  stage: extract_metadata

  tags:
    - bin-runner
  script:
    - python3 $CI_PROJECT_DIR/SecOps/pipeline/py-scripts/extract_gitlab_metadata.py $CI_PROJECT_DIR/SecOps/artifacts/metadata.json
  artifacts:
    paths:
      - $CI_PROJECT_DIR/SecOps/artifacts/metadata.json
    when: always


# Stage 3 run pen tests
run_pen_test:
  stage: run_pen_test
  tags:
    - bin-runner
  image: ghcr.io/zaproxy/zaproxy:stable
  script:
    # Run your command and capture its output.
    - mkdir -p SecOps/artifacts
    - START_TIME=$(date +%s)
    - /home/gitlab-runner/zap/zap.sh -cmd -script "$CI_PROJECT_DIR/zest-scrips/sql_injection_fail.zst" > $CI_PROJECT_DIR/SecOps/artifacts/output.txt
    - /home/gitlab-runner/zap/zap.sh -cmd -script "$CI_PROJECT_DIR/zest-scrips/premium_key_get.zst" >> $CI_PROJECT_DIR/SecOps/artifacts/output.txt
    - /home/gitlab-runner/zap/zap.sh -cmd -script "$CI_PROJECT_DIR/zest-scrips/sql_injection_login_2.zst" >> $CI_PROJECT_DIR/SecOps/artifacts/output.txt
    # - docker run -v ./zest-scripts:/zap/wrk/:rw -t ghcr.io/zaproxy/zaproxy:stable zap.sh -cmd -script wrk/sql_injection_fail.zst > data/output.txt
    # - docker run -v ./zest-scripts:/zap/wrk/:rw -t ghcr.io/zaproxy/zaproxy:stable zap.sh -cmd -script wrk/premium_key_get.zst >> data/output.txt
    # - docker run -v ./zest-scripts:/zap/wrk/:rw -t ghcr.io/zaproxy/zaproxy:stable zap.sh -cmd -script wrk/sql_injection_login_2.zst >> data/output.txt
    - END_TIME=$(date +%s)
    - 'echo "Time taken: $((END_TIME - START_TIME)) seconds" >> $CI_PROJECT_DIR/SecOps/artifacts/output.txt'
    - 'echo "Test Suite: Zest Security Tests" >> $CI_PROJECT_DIR/SecOps/artifacts/output.txt'
    - 'echo "Test Type: advanced" >> $CI_PROJECT_DIR/SecOps/artifacts/output.txt'
    - 'echo "Category: general" >> $CI_PROJECT_DIR/SecOps/artifacts/output.txt'
    - python3 SecOps/pipeline/py-scripts/json_processing.py $CI_PROJECT_DIR/SecOps/artifacts/output.txt $CI_PROJECT_DIR/SecOps/artifacts/output.json $CI_PROJECT_DIR/SecOps/artifacts/metadata.json
  # Artifacts are saved even if the job fails:
  artifacts:
    when: always
    paths:
      - $CI_PROJECT_DIR/SecOps/artifacts/output.txt
      - $CI_PROJECT_DIR/SecOps/artifacts/output.json




# Stage 4 save JSON data to PostgreSQL
save_results:
  image: python:3.9
  stage: save_results
  needs:
    - run_pen_test
  before_script:
    # Create a virtual environment
    - python3 -m venv venv

    # Activate the virtual environment
    - source venv/bin/activate

    # Now we can safely install packages in our isolated environment
    - python3 -m pip install --upgrade pip
    - python3 -m pip install psycopg2-binary python-dotenv

    # Verify our environment
    - echo "Python environment information:"
    - which python3
    - python3 --version
    - pip list

    # Show our working directory and content
    - echo "Current directory structure:"
    - pwd
    - ls -la

  tags:
    - bin-runner

  script:
    # Make sure we're still in our virtual environment when running the script
    - source venv/bin/activate
    - python3 SecOps/pipeline/py-scripts/send_test_results_to_SQL.py $CI_PROJECT_DIR/SecOps/artifacts/output.json

  artifacts:
    paths:
      - SecOps/artifacts
    when: always
  allow_failure: false


# Stage 5 Grafana
grafana_visualization:

  stage: visualize

  before_script:
    - echo "Starting cleanup at $(date)"
    - sudo rm -rf $CI_PROJECT_DIR/grafana/provisioning || true
    - echo "Creating directories at $(date)" 

  tags:
    - bin-runner
  script:
  - echo "Stopping any existing Grafana container..."
  - docker stop grafana || true
  - docker rm grafana || true
  
  - echo "Starting Grafana with PostgreSQL as its database and provisioning settings..."
  - docker run -d --name=grafana --network=host
      --user "$(id -u gitlab-runner):$(id -g gitlab-runner)"
      -v grafana_data:/var/lib/grafana
      -v ~/project/sweng25_group36-workdaysecurity/Grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
      -v ~/project/sweng25_group36-workdaysecurity/Grafana/provisioning/datasources:/etc/grafana/provisioning/datasources
      -e "GF_SERVER_HTTP_PORT=4000"
      grafana/grafana:latest
  
  - sleep 20
  
  - echo "Checking Grafana logs..."
  - docker logs grafana
  
  - echo "Testing Grafana provisioning..."
  - curl -s -u admin:admin http://172.20.10.12:4000/api/search?query=


